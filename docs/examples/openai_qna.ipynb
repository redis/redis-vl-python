{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question and Answer with OpenAI and RedisVL\n",
    "\n",
    "This example shows how to use RedisVL to create a question and answer system using OpenAI's API.\n",
    "\n",
    "In this notebook we will\n",
    "1. Download a dataset of wikipedia articles (thanks to OpenAI's CDN)\n",
    "2. Create embeddings for each article\n",
    "3. Create a RedisVL index and store the embeddings with metadata\n",
    "4. Construct a simple QnA system using the index and GPT-3\n",
    "5. Improve the QnA system with LLMCache\n",
    "\n",
    "\n",
    "The image below shows the architecture of the system we will create in this notebook.\n",
    "\n",
    "![Diagram](https://github.com/RedisVentures/redis-openai-qna/raw/main/app/assets/RedisOpenAI-QnA-Architecture.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "In order to run this example, you will need to have a Redis instance with RediSearch running locally. You can do this by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "docker run --name redis-vecdb -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
    "```\n",
    "\n",
    "This will also provide the RedisInsight GUI at http://localhost:8001\n",
    "\n",
    "Next, we will install the dependencies for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we need to install a few things\n",
    "\n",
    "!pip install pandas wget tenacity tiktoken openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wikipedia_articles_2000.csv'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wget\n",
    "import pandas as pd\n",
    "\n",
    "embeddings_url = 'https://cdn.openai.com/API/examples/data/wikipedia_articles_2000.csv'\n",
    "\n",
    "wget.download(embeddings_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3661</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Photon</td>\n",
       "      <td>Photon</td>\n",
       "      <td>Photons  (from Greek φως, meaning light), in m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7796</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Thomas%20Dolby</td>\n",
       "      <td>Thomas Dolby</td>\n",
       "      <td>Thomas Dolby (born Thomas Morgan Robertson; 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67912</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Embroidery</td>\n",
       "      <td>Embroidery</td>\n",
       "      <td>Embroidery is the art of decorating fabric or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44309</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Consecutive%...</td>\n",
       "      <td>Consecutive integer</td>\n",
       "      <td>Consecutive numbers are numbers that follow ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41741</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/German%20Empire</td>\n",
       "      <td>German Empire</td>\n",
       "      <td>The German Empire (\"Deutsches Reich\" or \"Deuts...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                                url  \\\n",
       "0   3661           https://simple.wikipedia.org/wiki/Photon   \n",
       "1   7796   https://simple.wikipedia.org/wiki/Thomas%20Dolby   \n",
       "2  67912       https://simple.wikipedia.org/wiki/Embroidery   \n",
       "3  44309  https://simple.wikipedia.org/wiki/Consecutive%...   \n",
       "4  41741  https://simple.wikipedia.org/wiki/German%20Empire   \n",
       "\n",
       "                 title                                               text  \n",
       "0               Photon  Photons  (from Greek φως, meaning light), in m...  \n",
       "1         Thomas Dolby  Thomas Dolby (born Thomas Morgan Robertson; 14...  \n",
       "2           Embroidery  Embroidery is the art of decorating fabric or ...  \n",
       "3  Consecutive integer  Consecutive numbers are numbers that follow ea...  \n",
       "4        German Empire  The German Empire (\"Deutsches Reich\" or \"Deuts...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wikipedia_articles_2000.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Chunking\n",
    "\n",
    "In order to create embeddings for the articles, we will need to chunk the text into smaller pieces. This is because there is a maximum length of text that can be sent to the OpenAI API. The code that follows pulls heavily from this [notebook](https://github.com/openai/openai-cookbook/blob/main/apps/enterprise-knowledge-retrieval/enterprise_knowledge_retrieval.ipynb) by OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_EMBEDDING_CHUNK_SIZE = 1000\n",
    "EMBEDDINGS_MODEL = \"text-embedding-ada-002\"\n",
    "\n",
    "\n",
    "def chunks(text, n, tokenizer):\n",
    "    tokens = tokenizer.encode(text)\n",
    "    \"\"\"Yield successive n-sized chunks from text.\n",
    "\n",
    "    Split a text into smaller chunks of size n, preferably ending at the end of a sentence\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        # Find the nearest end of sentence within a range of 0.5 * n and 1.5 * n tokens\n",
    "        j = min(i + int(1.5 * n), len(tokens))\n",
    "        while j > i + int(0.5 * n):\n",
    "            # Decode the tokens and check for full stop or newline\n",
    "            chunk = tokenizer.decode(tokens[i:j])\n",
    "            if chunk.endswith(\".\") or chunk.endswith(\"\\n\"):\n",
    "                break\n",
    "            j -= 1\n",
    "        # If no end of sentence found, use n tokens as the chunk size\n",
    "        if j == i + int(0.5 * n):\n",
    "            j = min(i + n, len(tokens))\n",
    "        yield tokens[i:j]\n",
    "        i = j\n",
    "\n",
    "def get_unique_id_for_file_chunk(title, chunk_index):\n",
    "    return str(title+\"-!\"+str(chunk_index))\n",
    "\n",
    "def chunk_text(record, tokenizer):\n",
    "    chunked_records = []\n",
    "\n",
    "    url = record['url']\n",
    "    title = record['title']\n",
    "    file_body_string = record['text']\n",
    "\n",
    "    \"\"\"Return a list of tuples (text_chunk, embedding) for a text.\"\"\"\n",
    "    token_chunks = list(chunks(file_body_string, TEXT_EMBEDDING_CHUNK_SIZE, tokenizer))\n",
    "    text_chunks = [f'Title: {title};\\n'+ tokenizer.decode(chunk) for chunk in token_chunks]\n",
    "\n",
    "    for i, text_chunk in enumerate(text_chunks):\n",
    "        doc_id = get_unique_id_for_file_chunk(title, i)\n",
    "        chunked_records.append(({\"id\": doc_id,\n",
    "                                \"url\": url,\n",
    "                                \"title\": title,\n",
    "                                \"content\": text_chunk,\n",
    "                                \"file_chunk_index\": i}))\n",
    "    return chunked_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise tokenizer\n",
    "import tiktoken\n",
    "oai_tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "records = []\n",
    "for _, record in df.iterrows():\n",
    "    records.extend(chunk_text(record, oai_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>file_chunk_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photon-!0</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Photon</td>\n",
       "      <td>Photon</td>\n",
       "      <td>Title: Photon;\\nPhotons  (from Greek φως, mean...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Photon-!1</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Photon</td>\n",
       "      <td>Photon</td>\n",
       "      <td>Title: Photon;\\nElementary particles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thomas Dolby-!0</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Thomas%20Dolby</td>\n",
       "      <td>Thomas Dolby</td>\n",
       "      <td>Title: Thomas Dolby;\\nThomas Dolby (born Thoma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embroidery-!0</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Embroidery</td>\n",
       "      <td>Embroidery</td>\n",
       "      <td>Title: Embroidery;\\nEmbroidery is the art of d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consecutive integer-!0</td>\n",
       "      <td>https://simple.wikipedia.org/wiki/Consecutive%...</td>\n",
       "      <td>Consecutive integer</td>\n",
       "      <td>Title: Consecutive integer;\\nConsecutive numbe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id                                                url  \\\n",
       "0               Photon-!0           https://simple.wikipedia.org/wiki/Photon   \n",
       "1               Photon-!1           https://simple.wikipedia.org/wiki/Photon   \n",
       "2         Thomas Dolby-!0   https://simple.wikipedia.org/wiki/Thomas%20Dolby   \n",
       "3           Embroidery-!0       https://simple.wikipedia.org/wiki/Embroidery   \n",
       "4  Consecutive integer-!0  https://simple.wikipedia.org/wiki/Consecutive%...   \n",
       "\n",
       "                 title                                            content  \\\n",
       "0               Photon  Title: Photon;\\nPhotons  (from Greek φως, mean...   \n",
       "1               Photon               Title: Photon;\\nElementary particles   \n",
       "2         Thomas Dolby  Title: Thomas Dolby;\\nThomas Dolby (born Thoma...   \n",
       "3           Embroidery  Title: Embroidery;\\nEmbroidery is the art of d...   \n",
       "4  Consecutive integer  Title: Consecutive integer;\\nConsecutive numbe...   \n",
       "\n",
       "   file_chunk_index  \n",
       "0                 0  \n",
       "1                 1  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunked_data = pd.DataFrame(records)\n",
    "chunked_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Creation\n",
    "\n",
    "With the text broken up into chunks, we can create embeddings with the RedisVL `OpenAITextVectorizer`. This provider uses the OpenAI API to create embeddings for the text. The code below shows how to create embeddings for the text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "from redisvl.vectorize.text import OpenAITextVectorizer\n",
    "\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\") or getpass.getpass(\"Enter your OpenAI API key: \")\n",
    "oaip = OpenAITextVectorizer(EMBEDDINGS_MODEL, api_config={\"api_key\": api_key})\n",
    "\n",
    "chunked_data[\"embedding\"] = oaip.embed_many(chunked_data[\"content\"].tolist(), as_buffer=True)\n",
    "chunked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the ``SearchIndex``\n",
    "\n",
    "Now that we have the embeddings, we can create a ``SearchIndex`` to store them in Redis. We will use the ``SearchIndex`` to store the embeddings and metadata for each article."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing wiki_schema.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile wiki_schema.yaml\n",
    "\n",
    "index:\n",
    "    name: wiki\n",
    "    prefix: oaiWiki\n",
    "\n",
    "fields:\n",
    "    text:\n",
    "        - name: content\n",
    "        - name: title\n",
    "    tag:\n",
    "        - name: id\n",
    "    vector:\n",
    "        - name: embedding\n",
    "          dims: 1536\n",
    "          distance_metric: cosine\n",
    "          algorithm: flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.index import AsyncSearchIndex\n",
    "\n",
    "index = AsyncSearchIndex.from_yaml(\"wiki_schema.yaml\")\n",
    "index.connect(\"redis://localhost:6379\")\n",
    "\n",
    "await index.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m14:48:22\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   Indices:\n",
      "\u001b[32m14:48:22\u001b[0m \u001b[34m[RedisVL]\u001b[0m \u001b[1;30mINFO\u001b[0m   1. wiki\n"
     ]
    }
   ],
   "source": [
    "!rvl index listall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "await index.load(chunked_data.to_dict(orient=\"records\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the QnA System\n",
    "\n",
    "Now that we have the data and the embeddings, we can build the QnA system. The system will perform three actions\n",
    "\n",
    "1. Embed the user question and search for the most similar content\n",
    "2. Make a prompt with the query and retrieved content\n",
    "3. Send the prompt to the OpenAI API and return the answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from redisvl.query import VectorQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHAT_MODEL = \"gpt-3.5-turbo\"\n",
    "\n",
    "def make_prompt(query, content):\n",
    "    retrieval_prompt = f'''Use the content to answer the search query the customer has sent.\n",
    "    If you can't answer the user's question, do not guess. If there is no content, respond with \"I don't know\".\n",
    "\n",
    "    Search query:\n",
    "\n",
    "    {query}\n",
    "\n",
    "    Content:\n",
    "\n",
    "    {content}\n",
    "\n",
    "    Answer:\n",
    "    '''\n",
    "    return retrieval_prompt\n",
    "\n",
    "async def retrieve_context(query):\n",
    "    # Embed the query\n",
    "    query_embedding = oaip.embed(query)\n",
    "\n",
    "    # Get the top result from the index\n",
    "    vector_query = VectorQuery(\n",
    "        vector=query_embedding,\n",
    "        vector_field_name=\"embedding\",\n",
    "        return_fields=[\"content\"],\n",
    "        num_results=1\n",
    "    )\n",
    "\n",
    "    results = await index.query(vector_query)\n",
    "    content = \"\"\n",
    "    if len(results) > 1:\n",
    "        content = results[0][\"content\"]\n",
    "    return content\n",
    "\n",
    "async def answer_question(query):\n",
    "    # Retrieve the context\n",
    "    content = await retrieve_context(query)\n",
    "\n",
    "    prompt = make_prompt(query, content)\n",
    "    retrieval = await openai.ChatCompletion.acreate(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[{'role':\"user\",\n",
    "                   'content': prompt}],\n",
    "        max_tokens=500)\n",
    "\n",
    "    # Response provided by GPT-3.5\n",
    "    return retrieval['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Brontosaurus is a large, herbivorous dinosaur that lived during the Late',\n",
       " 'Jurassic period. It is known for its long neck and tail, as well as its massive',\n",
       " 'size. The Brontosaurus is part of the sauropod family of dinosaurs and is often',\n",
       " 'depicted as peacefully grazing on vegetation. However, it is important to note',\n",
       " 'that the Brontosaurus was once thought to have been the same as the Apatosaurus,',\n",
       " 'but recent research has indicated that they are two distinct species.']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "question = \"What is a Brontosaurus?\"\n",
    "textwrap.wrap(await answer_question(question), width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I don't know.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question that makes no sense\n",
    "question = \"What is a trackiosamidon?\"\n",
    "await answer_question(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alanis Morissette is a Canadian-American singer, songwriter, and',\n",
       " 'actress. She rose to fame in the 1990s with her album \"Jagged Little',\n",
       " 'Pill,\" which became a major hit and earned her several Grammy Awards,',\n",
       " 'including Album of the Year. Morissette is known for her introspective',\n",
       " 'and confessional songwriting style, often addressing themes of love,',\n",
       " 'relationships, and personal struggles in her music. Apart from her',\n",
       " 'successful music career, she has also ventured into acting and has',\n",
       " 'appeared in various films and TV shows. Overall, Alanis Morissette has',\n",
       " 'had a significant impact on the music industry and continues to',\n",
       " 'inspire fans with her powerful and emotional performances.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Tell me about the life of Alanis Morissette\"\n",
    "textwrap.wrap(await answer_question(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the QnA System with LLMCache\n",
    "\n",
    "The QnA system we built above is pretty good, but it can be improved. We can use the ``LLMCache`` to improve the system. The ``LLMCache`` will store the results of previous queries and return them if the query is similar enough to a previous query. This will reduce the number of queries we need to send to the OpenAI API and increase the overall QPS of the system assuming we expect similar queries to be asked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.llmcache.semantic import SemanticCache\n",
    "\n",
    "cache = SemanticCache(redis_url=\"redis://localhost:6379\", threshold=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def answer_question(query):\n",
    "\n",
    "    # check the cache\n",
    "    result = cache.check(prompt=query)\n",
    "    if result:\n",
    "        return result[0]\n",
    "\n",
    "    # Retrieve the context\n",
    "    content = await retrieve_context(query)\n",
    "\n",
    "    prompt = make_prompt(query, content)\n",
    "    retrieval = await openai.ChatCompletion.acreate(\n",
    "        model=CHAT_MODEL,\n",
    "        messages=[{'role':\"user\",\n",
    "                   'content': prompt}],\n",
    "        max_tokens=500)\n",
    "\n",
    "    # Response provided by GPT-3.5\n",
    "    answer = retrieval['choices'][0]['message']['content']\n",
    "\n",
    "    # cache the query_embedding and answer\n",
    "    cache.store(query, answer)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 11.857624769210815\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alanis Morissette is a Canadian-American singer, songwriter, and actress. She',\n",
       " 'was born on June 1, 1974, in Ottawa, Canada. Morissette began her music career',\n",
       " 'in the early 1990s and gained international recognition with her third studio',\n",
       " 'album, \"Jagged Little Pill,\" released in 1995. The album was a huge commercial',\n",
       " 'success, selling millions of copies worldwide and earning Morissette several',\n",
       " 'Grammy Awards.  Throughout her career, Morissette has released numerous',\n",
       " 'successful albums and has continued to evolve her musical style, incorporating',\n",
       " 'elements of rock, pop, and alternative music. Some of her popular songs include',\n",
       " '\"You Oughta Know,\" \"Ironic,\" and \"Hand in My Pocket.\"  Besides music, Morissette',\n",
       " 'has also ventured into acting, with appearances in movies and TV shows. She has',\n",
       " 'been involved in various philanthropic activities and has spoken openly about',\n",
       " 'her personal struggles with eating disorders and mental health.  Overall, Alanis',\n",
       " 'Morissette has had a successful and influential career in the music industry,',\n",
       " 'leaving a lasting impact with her powerful and introspective lyrics.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask a question to cache an answer\n",
    "import time\n",
    "start = time.time()\n",
    "question = \"Tell me about the life of Alanis Morissette\"\n",
    "answer = await answer_question(question)\n",
    "print(f\"Time taken: {time.time() - start}\\n\")\n",
    "textwrap.wrap(answer, width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with cache: 0.22634601593017578\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alanis Morissette is a Canadian-American singer, songwriter, and actress. She',\n",
       " 'was born on June 1, 1974, in Ottawa, Canada. Morissette began her music career',\n",
       " 'in the early 1990s and gained international recognition with her third studio',\n",
       " 'album, \"Jagged Little Pill,\" released in 1995. The album was a huge commercial',\n",
       " 'success, selling millions of copies worldwide and earning Morissette several',\n",
       " 'Grammy Awards.  Throughout her career, Morissette has released numerous',\n",
       " 'successful albums and has continued to evolve her musical style, incorporating',\n",
       " 'elements of rock, pop, and alternative music. Some of her popular songs include',\n",
       " '\"You Oughta Know,\" \"Ironic,\" and \"Hand in My Pocket.\"  Besides music, Morissette',\n",
       " 'has also ventured into acting, with appearances in movies and TV shows. She has',\n",
       " 'been involved in various philanthropic activities and has spoken openly about',\n",
       " 'her personal struggles with eating disorders and mental health.  Overall, Alanis',\n",
       " 'Morissette has had a successful and influential career in the music industry,',\n",
       " 'leaving a lasting impact with her powerful and introspective lyrics.']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same question, return cached answer, save time, save money :)\n",
    "start = time.time()\n",
    "answer = await answer_question(question)\n",
    "print(f\"Time taken with cache: {time.time() - start}\\n\")\n",
    "textwrap.wrap(answer, width=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken with the cache: 0.48161983489990234\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Alanis Morissette is a Canadian-American singer, songwriter, and actress. She',\n",
       " 'was born on June 1, 1974, in Ottawa, Canada. Morissette began her music career',\n",
       " 'in the early 1990s and gained international recognition with her third studio',\n",
       " 'album, \"Jagged Little Pill,\" released in 1995. The album was a huge commercial',\n",
       " 'success, selling millions of copies worldwide and earning Morissette several',\n",
       " 'Grammy Awards.  Throughout her career, Morissette has released numerous',\n",
       " 'successful albums and has continued to evolve her musical style, incorporating',\n",
       " 'elements of rock, pop, and alternative music. Some of her popular songs include',\n",
       " '\"You Oughta Know,\" \"Ironic,\" and \"Hand in My Pocket.\"  Besides music, Morissette',\n",
       " 'has also ventured into acting, with appearances in movies and TV shows. She has',\n",
       " 'been involved in various philanthropic activities and has spoken openly about',\n",
       " 'her personal struggles with eating disorders and mental health.  Overall, Alanis',\n",
       " 'Morissette has had a successful and influential career in the music industry,',\n",
       " 'leaving a lasting impact with her powerful and introspective lyrics.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ask a semantically similar question returns the same answer from the cache\n",
    "# but isn't exactly the same question. In this case, the semantic similarity between\n",
    "# the questions is greater than the threshold of 0.8 the cache is set to.\n",
    "start = time.time()\n",
    "question = \"Who is Alanis Morissette?\"\n",
    "answer = await answer_question(question)\n",
    "print(f\"Time taken with the cache: {time.time() - start}\\n\")\n",
    "textwrap.wrap(answer, width=80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rvl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
