{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize Indexes with SVS-VAMANA\n",
    "\n",
    "This guide covers SVS-VAMANA (Scalable Vector Search with VAMANA graph algorithm), a graph-based vector search algorithm optimized for compression methods to reduce memory usage. It combines the Vamana graph algorithm with advanced compression techniques (LVQ and LeanVec) and is optimized for Intel hardware.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before you begin, ensure you have:\n",
    "- Installed RedisVL: `pip install redisvl`\n",
    "- A running Redis instance with Redis >= 8.2.0 and RediSearch >= 2.8.10 ([Redis 8+](https://redis.io/downloads/) or [Redis Cloud](https://redis.io/cloud))\n",
    "\n",
    "> **Note:** SVS-VAMANA only supports FLOAT16 and FLOAT32 datatypes.\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "By the end of this guide, you will be able to:\n",
    "- Understand when to use SVS-VAMANA for vector search\n",
    "- Configure compression settings for memory optimization\n",
    "- Use the CompressionAdvisor for automatic optimization\n",
    "- Trade off between memory usage, speed, and search quality\n",
    "\n",
    "**SVS-VAMANA offers:**\n",
    "- **Fast approximate nearest neighbor search** using graph-based algorithms\n",
    "- **Vector compression** (LVQ, LeanVec) with up to 87.5% memory savings\n",
    "- **Dimensionality reduction** (optional, with LeanVec)\n",
    "- **Automatic performance optimization** through CompressionAdvisor\n",
    "\n",
    "**Use SVS-VAMANA when:**\n",
    "- Large datasets where memory is expensive\n",
    "- Cloud deployments with memory-based pricing\n",
    "- When 90-95% recall is acceptable\n",
    "- High-dimensional vectors (>1024 dims) with LeanVec compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.utils import CompressionAdvisor\n",
    "from redisvl.redis.utils import array_to_buffer\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redis connection\n",
    "REDIS_URL = \"redis://localhost:6379\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start with CompressionAdvisor\n",
    "\n",
    "The easiest way to get started with SVS-VAMANA is using the `CompressionAdvisor` utility, which automatically recommends optimal configuration based on your vector dimensions and performance priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Configuration:\n",
      "  algorithm: svs-vamana\n",
      "  datatype: float16\n",
      "  graph_max_degree: 64\n",
      "  construction_window_size: 300\n",
      "  compression: LeanVec4x8\n",
      "  reduce: 512\n",
      "  search_window_size: 30\n",
      "\n",
      "Estimated Memory Savings: 81.2%\n"
     ]
    }
   ],
   "source": [
    "# Get recommended configuration for common embedding dimensions\n",
    "dims = 1024  # Common embedding dimensions (works reliably with SVS-VAMANA)\n",
    "\n",
    "config = CompressionAdvisor.recommend(\n",
    "    dims=dims,\n",
    "    priority=\"balanced\"  # Options: \"memory\", \"speed\", \"balanced\"\n",
    ")\n",
    "\n",
    "print(\"Recommended Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Estimate memory savings\n",
    "savings = CompressionAdvisor.estimate_memory_savings(\n",
    "    config[\"compression\"],\n",
    "    dims,\n",
    "    config.get(\"reduce\")\n",
    ")\n",
    "print(f\"\\nEstimated Memory Savings: {savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an SVS-VAMANA Index\n",
    "\n",
    "Let's create an index using the recommended configuration. We'll use a simple schema with text content and vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created SVS-VAMANA index: svs_demo\n",
      "   Algorithm: svs-vamana\n",
      "   Compression: LeanVec4x8\n",
      "   Dimensions: 1024\n",
      "   Reduced to: 512 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Create index schema with recommended SVS-VAMANA configuration\n",
    "schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"svs_demo\",\n",
    "        \"prefix\": \"doc\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"content\", \"type\": \"text\"},\n",
    "        {\"name\": \"category\", \"type\": \"tag\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": dims,\n",
    "                **config,  # Use the recommended configuration\n",
    "                \"distance_metric\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the index\n",
    "index = SearchIndex.from_dict(schema, redis_url=REDIS_URL)\n",
    "index.create(overwrite=True)\n",
    "\n",
    "print(f\"‚úÖ Created SVS-VAMANA index: {index.name}\")\n",
    "print(f\"   Algorithm: {config['algorithm']}\")\n",
    "print(f\"   Compression: {config['compression']}\")\n",
    "print(f\"   Dimensions: {dims}\")\n",
    "if 'reduce' in config:\n",
    "    print(f\"   Reduced to: {config['reduce']} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sample Data\n",
    "\n",
    "Let's create some sample documents with embeddings to demonstrate SVS-VAMANA search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vectors with 512 dimensions (reduced from 1024 if applicable)\n",
      "‚úÖ Loaded 10 documents into the index\n",
      "   Index now contains 0 documents\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data\n",
    "sample_documents = [\n",
    "    {\"content\": \"Machine learning algorithms for data analysis\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Natural language processing and text understanding\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Computer vision and image recognition systems\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Delicious pasta recipes from Italy\", \"category\": \"food\"},\n",
    "    {\"content\": \"Traditional French cooking techniques\", \"category\": \"food\"},\n",
    "    {\"content\": \"Healthy meal planning and nutrition\", \"category\": \"food\"},\n",
    "    {\"content\": \"Travel guide to European destinations\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Adventure hiking in mountain regions\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Cultural experiences in Asian cities\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Financial planning for retirement\", \"category\": \"finance\"},\n",
    "]\n",
    "\n",
    "# Generate random embeddings for demonstration\n",
    "# In practice, you would use a real embedding model\n",
    "data_to_load = []\n",
    "\n",
    "# Use reduced dimensions if LeanVec compression is applied\n",
    "vector_dims = config.get(\"reduce\", dims)\n",
    "print(f\"Creating vectors with {vector_dims} dimensions (reduced from {dims} if applicable)\")\n",
    "\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    # Create a random vector with some category-based clustering\n",
    "    base_vector = np.random.random(vector_dims).astype(np.float32)\n",
    "    \n",
    "    # Add some category-based similarity (optional, for demo purposes)\n",
    "    category_offset = hash(doc[\"category\"]) % 100 / 1000.0\n",
    "    base_vector[0] += category_offset\n",
    "    \n",
    "    # Convert to the datatype specified in config\n",
    "    if config[\"datatype\"] == \"float16\":\n",
    "        base_vector = base_vector.astype(np.float16)\n",
    "    \n",
    "    data_to_load.append({\n",
    "        \"content\": doc[\"content\"],\n",
    "        \"category\": doc[\"category\"],\n",
    "        \"embedding\": array_to_buffer(base_vector, dtype=config[\"datatype\"])\n",
    "    })\n",
    "\n",
    "# Load data into the index\n",
    "index.load(data_to_load)\n",
    "print(f\"‚úÖ Loaded {len(data_to_load)} documents into the index\")\n",
    "\n",
    "# Wait a moment for indexing to complete\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "# Verify the data was loaded\n",
    "info = index.info()\n",
    "print(f\"   Index now contains {info.get('num_docs', 0)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Vector Searches\n",
    "\n",
    "Now let's perform some vector similarity searches using our SVS-VAMANA index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Vector Search Results:\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a query vector (in practice, this would be an embedding of your query text)\n",
    "# Important: Query vector must match the index datatype and dimensions\n",
    "vector_dims = config.get(\"reduce\", dims)\n",
    "if config[\"datatype\"] == \"float16\":\n",
    "    query_vector = np.random.random(vector_dims).astype(np.float16)\n",
    "else:\n",
    "    query_vector = np.random.random(vector_dims).astype(np.float32)\n",
    "\n",
    "# Perform a vector similarity search\n",
    "query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "results = index.query(query)\n",
    "\n",
    "print(\"üîç Vector Search Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i, result in enumerate(results, 1):\n",
    "    distance = result.get('vector_distance', 'N/A')\n",
    "    print(f\"{i}. [{result['category']}] {result['content']}\")\n",
    "    print(f\"   Distance: {distance:.4f}\" if isinstance(distance, (int, float)) else f\"   Distance: {distance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime Parameters for Performance Tuning\n",
    "\n",
    "SVS-VAMANA supports runtime parameters that can be adjusted at query time without rebuilding the index. These parameters allow you to fine-tune the trade-off between search speed and accuracy.\n",
    "\n",
    "**Available Runtime Parameters:**\n",
    "\n",
    "- **`search_window_size`**: Controls the size of the search window during KNN search (higher = better recall, slower search)\n",
    "- **`epsilon`**: Approximation factor for range queries (default: 0.01)\n",
    "- **`use_search_history`**: Whether to use search buffer (OFF/ON/AUTO, default: AUTO)\n",
    "- **`search_buffer_capacity`**: Tuning parameter for 2-level compression (default: search_window_size)\n",
    "\n",
    "Let's see how these parameters affect search performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Basic query with default parameters\n",
    "basic_query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "print(\"üîç Basic Query (default parameters):\")\n",
    "results = index.query(basic_query)\n",
    "print(f\"Found {len(results)} results\\n\")\n",
    "\n",
    "# Example 2: Query with tuned runtime parameters for higher recall\n",
    "tuned_query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=5,\n",
    "    search_window_size=40,      # Larger window for better recall\n",
    "    use_search_history='ON',    # Use search history\n",
    "    search_buffer_capacity=50   # Larger buffer capacity\n",
    ")\n",
    "\n",
    "print(\"üéØ Tuned Query (higher recall parameters):\")\n",
    "results = index.query(tuned_query)\n",
    "print(f\"Found {len(results)} results\")\n",
    "print(\"\\nNote: Higher search_window_size improves recall but may increase latency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime Parameters with Range Queries\n",
    "\n",
    "Runtime parameters are also useful for range queries, where you want to find all vectors within a certain distance threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from redisvl.query import VectorRangeQuery\n",
    "\n",
    "# Range query with runtime parameters\n",
    "range_query = VectorRangeQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    distance_threshold=0.3,\n",
    "    epsilon=0.05,               # Approximation factor\n",
    "    search_window_size=30,      # Search window size\n",
    "    use_search_history='AUTO'   # Automatic history management\n",
    ")\n",
    "\n",
    "results = index.query(range_query)\n",
    "print(f\"üéØ Range Query Results: Found {len(results)} vectors within distance threshold 0.3\")\n",
    "for i, result in enumerate(results[:3], 1):\n",
    "    distance = result.get('vector_distance', 'N/A')\n",
    "    print(f\"{i}. {result['content'][:50]}... (distance: {distance})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Compression Types\n",
    "\n",
    "SVS-VAMANA supports different compression algorithms that trade off between memory usage and search quality. Let's explore the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Recommendations for Different Priorities:\n",
      "============================================================\n",
      "\n",
      "MEMORY Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 ‚Üí 512\n",
      "  Search window size: 20\n",
      "  Memory savings: 81.2%\n",
      "\n",
      "SPEED Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 ‚Üí 256\n",
      "  Search window size: 40\n",
      "  Memory savings: 90.6%\n",
      "\n",
      "BALANCED Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 ‚Üí 512\n",
      "  Search window size: 30\n",
      "  Memory savings: 81.2%\n"
     ]
    }
   ],
   "source": [
    "# Compare different compression priorities\n",
    "print(\"Compression Recommendations for Different Priorities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "priorities = [\"memory\", \"speed\", \"balanced\"]\n",
    "for priority in priorities:\n",
    "    config = CompressionAdvisor.recommend(dims=dims, priority=priority)\n",
    "    savings = CompressionAdvisor.estimate_memory_savings(\n",
    "        config[\"compression\"],\n",
    "        dims,\n",
    "        config.get(\"reduce\")\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{priority.upper()} Priority:\")\n",
    "    print(f\"  Compression: {config['compression']}\")\n",
    "    print(f\"  Datatype: {config['datatype']}\")\n",
    "    if \"reduce\" in config:\n",
    "        print(f\"  Dimensionality reduction: {dims} ‚Üí {config['reduce']}\")\n",
    "    print(f\"  Search window size: {config['search_window_size']}\")\n",
    "    print(f\"  Memory savings: {savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression Types Explained\n",
    "\n",
    "SVS-VAMANA offers several compression algorithms:\n",
    "\n",
    "### LVQ (Learned Vector Quantization)\n",
    "- **LVQ4**: 4 bits per dimension (87.5% memory savings)\n",
    "- **LVQ4x4**: 8 bits per dimension (75% memory savings)\n",
    "- **LVQ4x8**: 12 bits per dimension (62.5% memory savings)\n",
    "- **LVQ8**: 8 bits per dimension (75% memory savings)\n",
    "\n",
    "### LeanVec (Compression + Dimensionality Reduction)\n",
    "- **LeanVec4x8**: 12 bits per dimension + dimensionality reduction\n",
    "- **LeanVec8x8**: 16 bits per dimension + dimensionality reduction\n",
    "\n",
    "The CompressionAdvisor automatically chooses the best compression type based on your vector dimensions and priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Savings by Vector Dimension:\n",
      "==================================================\n",
      "Dims   Compression  Savings  Strategy\n",
      "--------------------------------------------------\n",
      "384    LVQ4x4         75.0% LVQ\n",
      "768    LVQ4x4         75.0% LVQ\n",
      "1024   LeanVec4x8     81.2% LeanVec\n",
      "1536   LeanVec4x8     81.2% LeanVec\n",
      "3072   LeanVec4x8     81.2% LeanVec\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate compression savings for different vector dimensions\n",
    "test_dimensions = [384, 768, 1024, 1536, 3072]\n",
    "\n",
    "print(\"Memory Savings by Vector Dimension:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Dims':<6} {'Compression':<12} {'Savings':<8} {'Strategy'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for dims in test_dimensions:\n",
    "    config = CompressionAdvisor.recommend(dims=dims, priority=\"balanced\")\n",
    "    savings = CompressionAdvisor.estimate_memory_savings(\n",
    "        config[\"compression\"],\n",
    "        dims,\n",
    "        config.get(\"reduce\")\n",
    "    )\n",
    "    \n",
    "    strategy = \"LeanVec\" if dims >= 1024 else \"LVQ\"\n",
    "    print(f\"{dims:<6} {config['compression']:<12} {savings:>6.1f}% {strategy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Queries with SVS-VAMANA\n",
    "\n",
    "SVS-VAMANA can be combined with other Redis search capabilities for powerful hybrid queries that filter by metadata while performing vector similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Hybrid Search Results (Technology category only):\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search: vector similarity + category filter\n",
    "hybrid_query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "# Add a filter to only search within \"technology\" category\n",
    "hybrid_query.set_filter(\"@category:{technology}\")\n",
    "\n",
    "filtered_results = index.query(hybrid_query)\n",
    "\n",
    "print(\"üîç Hybrid Search Results (Technology category only):\")\n",
    "print(\"=\" * 55)\n",
    "for i, result in enumerate(filtered_results, 1):\n",
    "    distance = result.get('vector_distance', 'N/A')\n",
    "    print(f\"{i}. [{result['category']}] {result['content']}\")\n",
    "    print(f\"   Distance: {distance:.4f}\" if isinstance(distance, (int, float)) else f\"   Distance: {distance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Monitoring\n",
    "\n",
    "Let's examine the index statistics to understand the performance characteristics of our SVS-VAMANA index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Index Statistics:\n",
      "==============================\n",
      "Documents: 0\n",
      "Vector index size: 0.00 MB\n",
      "Total indexing time: 1.58 seconds\n",
      "Memory efficiency calculation requires documents and vector index size > 0\n"
     ]
    }
   ],
   "source": [
    "# Get detailed index information\n",
    "info = index.info()\n",
    "\n",
    "print(\"üìä Index Statistics:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Documents: {info.get('num_docs', 0)}\")\n",
    "\n",
    "# Handle vector_index_sz_mb which might be a string\n",
    "vector_size = info.get('vector_index_sz_mb', 0)\n",
    "if isinstance(vector_size, str):\n",
    "    try:\n",
    "        vector_size = float(vector_size)\n",
    "    except ValueError:\n",
    "        vector_size = 0.0\n",
    "print(f\"Vector index size: {vector_size:.2f} MB\")\n",
    "\n",
    "# Handle total_indexing_time which might also be a string\n",
    "indexing_time = info.get('total_indexing_time', 0)\n",
    "if isinstance(indexing_time, str):\n",
    "    try:\n",
    "        indexing_time = float(indexing_time)\n",
    "    except ValueError:\n",
    "        indexing_time = 0.0\n",
    "print(f\"Total indexing time: {indexing_time:.2f} seconds\")\n",
    "\n",
    "# Calculate memory efficiency\n",
    "if info.get('num_docs', 0) > 0 and vector_size > 0:\n",
    "    mb_per_doc = vector_size / info.get('num_docs', 1)\n",
    "    print(f\"Memory per document: {mb_per_doc:.4f} MB\")\n",
    "    \n",
    "    # Estimate for larger datasets\n",
    "    for scale in [1000, 10000, 100000]:\n",
    "        estimated_mb = mb_per_doc * scale\n",
    "        print(f\"Estimated size for {scale:,} docs: {estimated_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"Memory efficiency calculation requires documents and vector index size > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Manual Configuration\n",
    "\n",
    "For advanced users who want full control over SVS-VAMANA parameters, you can manually configure the algorithm instead of using CompressionAdvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual SVS-VAMANA Configuration:\n",
      "========================================\n",
      "  algorithm: svs-vamana\n",
      "  datatype: float32\n",
      "  distance_metric: cosine\n",
      "  graph_max_degree: 64\n",
      "  construction_window_size: 300\n",
      "  search_window_size: 40\n",
      "  compression: LVQ4x4\n",
      "  training_threshold: 10000\n",
      "\n",
      "Estimated memory savings: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Example of manual SVS-VAMANA configuration\n",
    "manual_schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"svs_manual\",\n",
    "        \"prefix\": \"manual\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"content\", \"type\": \"text\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": 768,\n",
    "                \"algorithm\": \"svs-vamana\",\n",
    "                \"datatype\": \"float32\",\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \n",
    "                # Graph construction parameters\n",
    "                \"graph_max_degree\": 64,           # Higher = better recall, more memory\n",
    "                \"construction_window_size\": 300,  # Higher = better quality, slower build\n",
    "                \n",
    "                # Search parameters\n",
    "                \"search_window_size\": 40,         # Higher = better recall, slower search\n",
    "                \n",
    "                # Compression settings\n",
    "                \"compression\": \"LVQ4x4\",          # Choose compression type\n",
    "                \"training_threshold\": 10000,      # Min vectors before compression training\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Manual SVS-VAMANA Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "vector_attrs = manual_schema[\"fields\"][1][\"attrs\"]\n",
    "for key, value in vector_attrs.items():\n",
    "    if key != \"dims\":  # Skip dims as it's obvious\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate memory savings for this configuration\n",
    "manual_savings = CompressionAdvisor.estimate_memory_savings(\n",
    "    \"LVQ4x4\", 768, None\n",
    ")\n",
    "print(f\"\\nEstimated memory savings: {manual_savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "### When to Use SVS-VAMANA\n",
    "- **Large datasets** (>10K vectors) where memory efficiency matters\n",
    "- **High-dimensional vectors** (>512 dimensions) that benefit from compression\n",
    "- **Applications** that can tolerate slight recall trade-offs for speed and memory savings\n",
    "\n",
    "### Parameter Tuning Guidelines\n",
    "\n",
    "**Index-time parameters** (set during index creation):\n",
    "- **Start with CompressionAdvisor** recommendations for compression and datatype\n",
    "- **Use LeanVec** for high-dimensional vectors (‚â•1024 dims)\n",
    "- **Use LVQ** for lower-dimensional vectors (<1024 dims)\n",
    "- **graph_max_degree**: Higher values improve recall but increase memory usage\n",
    "- **construction_window_size**: Higher values improve index quality but slow down build time\n",
    "\n",
    "**Runtime parameters** (adjustable at query time without rebuilding index):\n",
    "- **search_window_size**: Start with 20, increase to 40-100 for higher recall\n",
    "- **epsilon**: Use 0.01-0.05 for range queries (higher = faster but less accurate)\n",
    "- **use_search_history**: Use 'AUTO' (default) or 'ON' for better recall\n",
    "- **search_buffer_capacity**: Usually set equal to search_window_size\n",
    "\n",
    "### Performance Considerations\n",
    "- **Index build time** increases with higher construction_window_size\n",
    "- **Search latency** increases with higher search_window_size (tunable at query time!)\n",
    "- **Memory usage** decreases with more aggressive compression\n",
    "- **Recall quality** may decrease with more aggressive compression or lower search_window_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Now that you understand SVS-VAMANA optimization, explore these related guides:\n",
    "\n",
    "- [Getting Started](01_getting_started.ipynb) - Learn the basics of RedisVL indexes\n",
    "- [Choose a Storage Type](05_hash_vs_json.ipynb) - Understand Hash vs JSON storage\n",
    "- [Query and Filter Data](02_complex_filtering.ipynb) - Apply filters to narrow down search results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Clean up the indices created in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up svs_demo index\n"
     ]
    }
   ],
   "source": [
    "# Clean up demo indices\n",
    "try:\n",
    "    index.delete()\n",
    "    print(\"Cleaned up svs_demo index\")\n",
    "except:\n",
    "    print(\"- svs_demo index was already deleted or doesn't exist\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
