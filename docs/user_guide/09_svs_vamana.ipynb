{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVS-VAMANA Vector Search\n",
    "\n",
    "In this notebook, we will explore SVS-VAMANA, a high-performance vector search algorithm that provides fast approximate nearest neighbor search with vector compression capabilities.\n",
    "\n",
    "SVS-VAMANA offers:\n",
    "- **Fast approximate nearest neighbor search** using graph-based algorithms\n",
    "- **Vector compression** (LVQ, LeanVec) with up to 87.5% memory savings\n",
    "- **Dimensionality reduction** (optional, with LeanVec)\n",
    "- **Automatic performance optimization** through CompressionAdvisor\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Prerequisites](#Prerequisites)\n",
    "2. [Quick Start with CompressionAdvisor](#Quick-Start-with-CompressionAdvisor)\n",
    "3. [Creating an SVS-VAMANA Index](#Creating-an-SVS-VAMANA-Index)\n",
    "4. [Loading Sample Data](#Loading-Sample-Data)\n",
    "5. [Performing Vector Searches](#Performing-Vector-Searches)\n",
    "6. [Understanding Compression Types](#Understanding-Compression-Types)\n",
    "7. [Hybrid Queries with SVS-VAMANA](#Hybrid-Queries-with-SVS-VAMANA)\n",
    "8. [Performance Monitoring](#Performance-Monitoring)\n",
    "9. [Manual Configuration (Advanced)](#Manual-Configuration-(Advanced))\n",
    "10. [Best Practices and Tips](#Best-Practices-and-Tips)\n",
    "11. [Cleanup](#Cleanup)\n",
    "\n",
    "---\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "1. Installed `redisvl` and have that environment active for this notebook\n",
    "2. A running Redis Stack instance with:\n",
    "   - Redis >= 8.2.0\n",
    "   - RediSearch >= 2.8.10\n",
    "\n",
    "For example, you can run Redis Stack locally with Docker:\n",
    "\n",
    "```bash\n",
    "docker run -d -p 6379:6379 -p 8001:8001 redis/redis-stack:latest\n",
    "```\n",
    "\n",
    "**Note:** SVS-VAMANA only supports FLOAT16 and FLOAT32 datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:08.569435Z",
     "iopub.status.busy": "2025-10-15T21:32:08.569310Z",
     "iopub.status.idle": "2025-10-15T21:32:08.696705Z",
     "shell.execute_reply": "2025-10-15T21:32:08.696395Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import numpy as np\n",
    "from redisvl.index import SearchIndex\n",
    "from redisvl.query import VectorQuery\n",
    "from redisvl.utils import CompressionAdvisor\n",
    "from redisvl.redis.utils import array_to_buffer\n",
    "\n",
    "# Set random seed for reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:08.697903Z",
     "iopub.status.busy": "2025-10-15T21:32:08.697811Z",
     "iopub.status.idle": "2025-10-15T21:32:08.699342Z",
     "shell.execute_reply": "2025-10-15T21:32:08.699114Z"
    }
   },
   "outputs": [],
   "source": [
    "# Redis connection\n",
    "REDIS_URL = \"redis://localhost:6379\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start with CompressionAdvisor\n",
    "\n",
    "The easiest way to get started with SVS-VAMANA is using the `CompressionAdvisor` utility, which automatically recommends optimal configuration based on your vector dimensions and performance priorities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:08.700313Z",
     "iopub.status.busy": "2025-10-15T21:32:08.700251Z",
     "iopub.status.idle": "2025-10-15T21:32:08.702206Z",
     "shell.execute_reply": "2025-10-15T21:32:08.702012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Configuration:\n",
      "  algorithm: svs-vamana\n",
      "  datatype: float16\n",
      "  graph_max_degree: 64\n",
      "  construction_window_size: 300\n",
      "  compression: LeanVec4x8\n",
      "  reduce: 512\n",
      "  search_window_size: 30\n",
      "\n",
      "Estimated Memory Savings: 81.2%\n"
     ]
    }
   ],
   "source": [
    "# Get recommended configuration for common embedding dimensions\n",
    "dims = 1024  # Common embedding dimensions (works reliably with SVS-VAMANA)\n",
    "\n",
    "config = CompressionAdvisor.recommend(\n",
    "    dims=dims,\n",
    "    priority=\"balanced\"  # Options: \"memory\", \"speed\", \"balanced\"\n",
    ")\n",
    "\n",
    "print(\"Recommended Configuration:\")\n",
    "for key, value in config.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Estimate memory savings\n",
    "savings = CompressionAdvisor.estimate_memory_savings(\n",
    "    config[\"compression\"],\n",
    "    dims,\n",
    "    config.get(\"reduce\")\n",
    ")\n",
    "print(f\"\\nEstimated Memory Savings: {savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an SVS-VAMANA Index\n",
    "\n",
    "Let's create an index using the recommended configuration. We'll use a simple schema with text content and vector embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:08.717380Z",
     "iopub.status.busy": "2025-10-15T21:32:08.717285Z",
     "iopub.status.idle": "2025-10-15T21:32:08.723852Z",
     "shell.execute_reply": "2025-10-15T21:32:08.723644Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Created SVS-VAMANA index: svs_demo\n",
      "   Algorithm: svs-vamana\n",
      "   Compression: LeanVec4x8\n",
      "   Dimensions: 1024\n",
      "   Reduced to: 512 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Create index schema with recommended SVS-VAMANA configuration\n",
    "schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"svs_demo\",\n",
    "        \"prefix\": \"doc\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"content\", \"type\": \"text\"},\n",
    "        {\"name\": \"category\", \"type\": \"tag\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": dims,\n",
    "                **config,  # Use the recommended configuration\n",
    "                \"distance_metric\": \"cosine\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create the index\n",
    "index = SearchIndex.from_dict(schema, redis_url=REDIS_URL)\n",
    "index.create(overwrite=True)\n",
    "\n",
    "print(f\"✅ Created SVS-VAMANA index: {index.name}\")\n",
    "print(f\"   Algorithm: {config['algorithm']}\")\n",
    "print(f\"   Compression: {config['compression']}\")\n",
    "print(f\"   Dimensions: {dims}\")\n",
    "if 'reduce' in config:\n",
    "    print(f\"   Reduced to: {config['reduce']} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Sample Data\n",
    "\n",
    "Let's create some sample documents with embeddings to demonstrate SVS-VAMANA search capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:08.724966Z",
     "iopub.status.busy": "2025-10-15T21:32:08.724905Z",
     "iopub.status.idle": "2025-10-15T21:32:10.740249Z",
     "shell.execute_reply": "2025-10-15T21:32:10.739174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating vectors with 512 dimensions (reduced from 1024 if applicable)\n",
      "✅ Loaded 10 documents into the index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Index now contains 0 documents\n"
     ]
    }
   ],
   "source": [
    "# Generate sample data\n",
    "sample_documents = [\n",
    "    {\"content\": \"Machine learning algorithms for data analysis\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Natural language processing and text understanding\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Computer vision and image recognition systems\", \"category\": \"technology\"},\n",
    "    {\"content\": \"Delicious pasta recipes from Italy\", \"category\": \"food\"},\n",
    "    {\"content\": \"Traditional French cooking techniques\", \"category\": \"food\"},\n",
    "    {\"content\": \"Healthy meal planning and nutrition\", \"category\": \"food\"},\n",
    "    {\"content\": \"Travel guide to European destinations\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Adventure hiking in mountain regions\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Cultural experiences in Asian cities\", \"category\": \"travel\"},\n",
    "    {\"content\": \"Financial planning for retirement\", \"category\": \"finance\"},\n",
    "]\n",
    "\n",
    "# Generate random embeddings for demonstration\n",
    "# In practice, you would use a real embedding model\n",
    "data_to_load = []\n",
    "\n",
    "# Use reduced dimensions if LeanVec compression is applied\n",
    "vector_dims = config.get(\"reduce\", dims)\n",
    "print(f\"Creating vectors with {vector_dims} dimensions (reduced from {dims} if applicable)\")\n",
    "\n",
    "for i, doc in enumerate(sample_documents):\n",
    "    # Create a random vector with some category-based clustering\n",
    "    base_vector = np.random.random(vector_dims).astype(np.float32)\n",
    "    \n",
    "    # Add some category-based similarity (optional, for demo purposes)\n",
    "    category_offset = hash(doc[\"category\"]) % 100 / 1000.0\n",
    "    base_vector[0] += category_offset\n",
    "    \n",
    "    # Convert to the datatype specified in config\n",
    "    if config[\"datatype\"] == \"float16\":\n",
    "        base_vector = base_vector.astype(np.float16)\n",
    "    \n",
    "    data_to_load.append({\n",
    "        \"content\": doc[\"content\"],\n",
    "        \"category\": doc[\"category\"],\n",
    "        \"embedding\": array_to_buffer(base_vector, dtype=config[\"datatype\"])\n",
    "    })\n",
    "\n",
    "# Load data into the index\n",
    "index.load(data_to_load)\n",
    "print(f\"✅ Loaded {len(data_to_load)} documents into the index\")\n",
    "\n",
    "# Wait a moment for indexing to complete\n",
    "import time\n",
    "time.sleep(2)\n",
    "\n",
    "# Verify the data was loaded\n",
    "info = index.info()\n",
    "print(f\"   Index now contains {info.get('num_docs', 0)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Vector Searches\n",
    "\n",
    "Now let's perform some vector similarity searches using our SVS-VAMANA index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.744612Z",
     "iopub.status.busy": "2025-10-15T21:32:10.744310Z",
     "iopub.status.idle": "2025-10-15T21:32:10.751707Z",
     "shell.execute_reply": "2025-10-15T21:32:10.751275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Vector Search Results:\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Create a query vector (in practice, this would be an embedding of your query text)\n",
    "# Important: Query vector must match the index datatype and dimensions\n",
    "vector_dims = config.get(\"reduce\", dims)\n",
    "if config[\"datatype\"] == \"float16\":\n",
    "    query_vector = np.random.random(vector_dims).astype(np.float16)\n",
    "else:\n",
    "    query_vector = np.random.random(vector_dims).astype(np.float32)\n",
    "\n",
    "# Perform a vector similarity search\n",
    "query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=5\n",
    ")\n",
    "\n",
    "results = index.query(query)\n",
    "\n",
    "print(\"🔍 Vector Search Results:\")\n",
    "print(\"=\" * 50)\n",
    "for i, result in enumerate(results, 1):\n",
    "    distance = result.get('vector_distance', 'N/A')\n",
    "    print(f\"{i}. [{result['category']}] {result['content']}\")\n",
    "    print(f\"   Distance: {distance:.4f}\" if isinstance(distance, (int, float)) else f\"   Distance: {distance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Compression Types\n",
    "\n",
    "SVS-VAMANA supports different compression algorithms that trade off between memory usage and search quality. Let's explore the available options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.753759Z",
     "iopub.status.busy": "2025-10-15T21:32:10.753565Z",
     "iopub.status.idle": "2025-10-15T21:32:10.757377Z",
     "shell.execute_reply": "2025-10-15T21:32:10.757018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compression Recommendations for Different Priorities:\n",
      "============================================================\n",
      "\n",
      "MEMORY Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 → 512\n",
      "  Search window size: 20\n",
      "  Memory savings: 81.2%\n",
      "\n",
      "SPEED Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 → 256\n",
      "  Search window size: 40\n",
      "  Memory savings: 90.6%\n",
      "\n",
      "BALANCED Priority:\n",
      "  Compression: LeanVec4x8\n",
      "  Datatype: float16\n",
      "  Dimensionality reduction: 1024 → 512\n",
      "  Search window size: 30\n",
      "  Memory savings: 81.2%\n"
     ]
    }
   ],
   "source": [
    "# Compare different compression priorities\n",
    "print(\"Compression Recommendations for Different Priorities:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "priorities = [\"memory\", \"speed\", \"balanced\"]\n",
    "for priority in priorities:\n",
    "    config = CompressionAdvisor.recommend(dims=dims, priority=priority)\n",
    "    savings = CompressionAdvisor.estimate_memory_savings(\n",
    "        config[\"compression\"],\n",
    "        dims,\n",
    "        config.get(\"reduce\")\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{priority.upper()} Priority:\")\n",
    "    print(f\"  Compression: {config['compression']}\")\n",
    "    print(f\"  Datatype: {config['datatype']}\")\n",
    "    if \"reduce\" in config:\n",
    "        print(f\"  Dimensionality reduction: {dims} → {config['reduce']}\")\n",
    "    print(f\"  Search window size: {config['search_window_size']}\")\n",
    "    print(f\"  Memory savings: {savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compression Types Explained\n",
    "\n",
    "SVS-VAMANA offers several compression algorithms:\n",
    "\n",
    "### LVQ (Learned Vector Quantization)\n",
    "- **LVQ4**: 4 bits per dimension (87.5% memory savings)\n",
    "- **LVQ4x4**: 8 bits per dimension (75% memory savings)\n",
    "- **LVQ4x8**: 12 bits per dimension (62.5% memory savings)\n",
    "- **LVQ8**: 8 bits per dimension (75% memory savings)\n",
    "\n",
    "### LeanVec (Compression + Dimensionality Reduction)\n",
    "- **LeanVec4x8**: 12 bits per dimension + dimensionality reduction\n",
    "- **LeanVec8x8**: 16 bits per dimension + dimensionality reduction\n",
    "\n",
    "The CompressionAdvisor automatically chooses the best compression type based on your vector dimensions and priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.759026Z",
     "iopub.status.busy": "2025-10-15T21:32:10.758895Z",
     "iopub.status.idle": "2025-10-15T21:32:10.762424Z",
     "shell.execute_reply": "2025-10-15T21:32:10.762083Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Savings by Vector Dimension:\n",
      "==================================================\n",
      "Dims   Compression  Savings  Strategy\n",
      "--------------------------------------------------\n",
      "384    LVQ4x4         75.0% LVQ\n",
      "768    LVQ4x4         75.0% LVQ\n",
      "1024   LeanVec4x8     81.2% LeanVec\n",
      "1536   LeanVec4x8     81.2% LeanVec\n",
      "3072   LeanVec4x8     81.2% LeanVec\n"
     ]
    }
   ],
   "source": [
    "# Demonstrate compression savings for different vector dimensions\n",
    "test_dimensions = [384, 768, 1024, 1536, 3072]\n",
    "\n",
    "print(\"Memory Savings by Vector Dimension:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Dims':<6} {'Compression':<12} {'Savings':<8} {'Strategy'}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for dims in test_dimensions:\n",
    "    config = CompressionAdvisor.recommend(dims=dims, priority=\"balanced\")\n",
    "    savings = CompressionAdvisor.estimate_memory_savings(\n",
    "        config[\"compression\"],\n",
    "        dims,\n",
    "        config.get(\"reduce\")\n",
    "    )\n",
    "    \n",
    "    strategy = \"LeanVec\" if dims >= 1024 else \"LVQ\"\n",
    "    print(f\"{dims:<6} {config['compression']:<12} {savings:>6.1f}% {strategy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid Queries with SVS-VAMANA\n",
    "\n",
    "SVS-VAMANA can be combined with other Redis search capabilities for powerful hybrid queries that filter by metadata while performing vector similarity search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.763978Z",
     "iopub.status.busy": "2025-10-15T21:32:10.763840Z",
     "iopub.status.idle": "2025-10-15T21:32:10.768306Z",
     "shell.execute_reply": "2025-10-15T21:32:10.768005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Hybrid Search Results (Technology category only):\n",
      "=======================================================\n"
     ]
    }
   ],
   "source": [
    "# Perform a hybrid search: vector similarity + category filter\n",
    "hybrid_query = VectorQuery(\n",
    "    vector=query_vector.tolist(),\n",
    "    vector_field_name=\"embedding\",\n",
    "    return_fields=[\"content\", \"category\"],\n",
    "    num_results=3\n",
    ")\n",
    "\n",
    "# Add a filter to only search within \"technology\" category\n",
    "hybrid_query.set_filter(\"@category:{technology}\")\n",
    "\n",
    "filtered_results = index.query(hybrid_query)\n",
    "\n",
    "print(\"🔍 Hybrid Search Results (Technology category only):\")\n",
    "print(\"=\" * 55)\n",
    "for i, result in enumerate(filtered_results, 1):\n",
    "    distance = result.get('vector_distance', 'N/A')\n",
    "    print(f\"{i}. [{result['category']}] {result['content']}\")\n",
    "    print(f\"   Distance: {distance:.4f}\" if isinstance(distance, (int, float)) else f\"   Distance: {distance}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Monitoring\n",
    "\n",
    "Let's examine the index statistics to understand the performance characteristics of our SVS-VAMANA index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.770248Z",
     "iopub.status.busy": "2025-10-15T21:32:10.770114Z",
     "iopub.status.idle": "2025-10-15T21:32:10.774772Z",
     "shell.execute_reply": "2025-10-15T21:32:10.774498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Index Statistics:\n",
      "==============================\n",
      "Documents: 0\n",
      "Vector index size: 0.00 MB\n",
      "Total indexing time: 1.36 seconds\n",
      "Memory efficiency calculation requires documents and vector index size > 0\n"
     ]
    }
   ],
   "source": [
    "# Get detailed index information\n",
    "info = index.info()\n",
    "\n",
    "print(\"📊 Index Statistics:\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Documents: {info.get('num_docs', 0)}\")\n",
    "\n",
    "# Handle vector_index_sz_mb which might be a string\n",
    "vector_size = info.get('vector_index_sz_mb', 0)\n",
    "if isinstance(vector_size, str):\n",
    "    try:\n",
    "        vector_size = float(vector_size)\n",
    "    except ValueError:\n",
    "        vector_size = 0.0\n",
    "print(f\"Vector index size: {vector_size:.2f} MB\")\n",
    "\n",
    "# Handle total_indexing_time which might also be a string\n",
    "indexing_time = info.get('total_indexing_time', 0)\n",
    "if isinstance(indexing_time, str):\n",
    "    try:\n",
    "        indexing_time = float(indexing_time)\n",
    "    except ValueError:\n",
    "        indexing_time = 0.0\n",
    "print(f\"Total indexing time: {indexing_time:.2f} seconds\")\n",
    "\n",
    "# Calculate memory efficiency\n",
    "if info.get('num_docs', 0) > 0 and vector_size > 0:\n",
    "    mb_per_doc = vector_size / info.get('num_docs', 1)\n",
    "    print(f\"Memory per document: {mb_per_doc:.4f} MB\")\n",
    "    \n",
    "    # Estimate for larger datasets\n",
    "    for scale in [1000, 10000, 100000]:\n",
    "        estimated_mb = mb_per_doc * scale\n",
    "        print(f\"Estimated size for {scale:,} docs: {estimated_mb:.1f} MB\")\n",
    "else:\n",
    "    print(\"Memory efficiency calculation requires documents and vector index size > 0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Configuration (Advanced)\n",
    "\n",
    "For advanced users who want full control over SVS-VAMANA parameters, you can manually configure the algorithm instead of using CompressionAdvisor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.776132Z",
     "iopub.status.busy": "2025-10-15T21:32:10.776038Z",
     "iopub.status.idle": "2025-10-15T21:32:10.779151Z",
     "shell.execute_reply": "2025-10-15T21:32:10.778875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual SVS-VAMANA Configuration:\n",
      "========================================\n",
      "  algorithm: svs-vamana\n",
      "  datatype: float32\n",
      "  distance_metric: cosine\n",
      "  graph_max_degree: 64\n",
      "  construction_window_size: 300\n",
      "  search_window_size: 40\n",
      "  compression: LVQ4x4\n",
      "  training_threshold: 10000\n",
      "\n",
      "Estimated memory savings: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Example of manual SVS-VAMANA configuration\n",
    "manual_schema = {\n",
    "    \"index\": {\n",
    "        \"name\": \"svs_manual\",\n",
    "        \"prefix\": \"manual\",\n",
    "    },\n",
    "    \"fields\": [\n",
    "        {\"name\": \"content\", \"type\": \"text\"},\n",
    "        {\n",
    "            \"name\": \"embedding\",\n",
    "            \"type\": \"vector\",\n",
    "            \"attrs\": {\n",
    "                \"dims\": 768,\n",
    "                \"algorithm\": \"svs-vamana\",\n",
    "                \"datatype\": \"float32\",\n",
    "                \"distance_metric\": \"cosine\",\n",
    "                \n",
    "                # Graph construction parameters\n",
    "                \"graph_max_degree\": 64,           # Higher = better recall, more memory\n",
    "                \"construction_window_size\": 300,  # Higher = better quality, slower build\n",
    "                \n",
    "                # Search parameters\n",
    "                \"search_window_size\": 40,         # Higher = better recall, slower search\n",
    "                \n",
    "                # Compression settings\n",
    "                \"compression\": \"LVQ4x4\",          # Choose compression type\n",
    "                \"training_threshold\": 10000,      # Min vectors before compression training\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Manual SVS-VAMANA Configuration:\")\n",
    "print(\"=\" * 40)\n",
    "vector_attrs = manual_schema[\"fields\"][1][\"attrs\"]\n",
    "for key, value in vector_attrs.items():\n",
    "    if key != \"dims\":  # Skip dims as it's obvious\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Calculate memory savings for this configuration\n",
    "manual_savings = CompressionAdvisor.estimate_memory_savings(\n",
    "    \"LVQ4x4\", 768, None\n",
    ")\n",
    "print(f\"\\nEstimated memory savings: {manual_savings}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "### When to Use SVS-VAMANA\n",
    "- **Large datasets** (>10K vectors) where memory efficiency matters\n",
    "- **High-dimensional vectors** (>512 dimensions) that benefit from compression\n",
    "- **Applications** that can tolerate slight recall trade-offs for speed and memory savings\n",
    "\n",
    "### Parameter Tuning Guidelines\n",
    "- **Start with CompressionAdvisor** recommendations\n",
    "- **Increase search_window_size** if you need higher recall\n",
    "- **Use LeanVec** for high-dimensional vectors (≥1024 dims)\n",
    "- **Use LVQ** for lower-dimensional vectors (<1024 dims)\n",
    "\n",
    "### Performance Considerations\n",
    "- **Index build time** increases with higher construction_window_size\n",
    "- **Search latency** increases with higher search_window_size\n",
    "- **Memory usage** decreases with more aggressive compression\n",
    "- **Recall quality** may decrease with more aggressive compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n",
    "\n",
    "Clean up the indices created in this demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T21:32:10.780645Z",
     "iopub.status.busy": "2025-10-15T21:32:10.780541Z",
     "iopub.status.idle": "2025-10-15T21:32:10.783383Z",
     "shell.execute_reply": "2025-10-15T21:32:10.783148Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned up svs_demo index\n",
      "\n",
      "🎉 SVS-VAMANA demo completed!\n",
      "\n",
      "Next steps:\n",
      "- Try SVS-VAMANA with your own embeddings\n",
      "- Experiment with different compression settings\n",
      "- Compare performance with FLAT and HNSW algorithms\n",
      "- Use hybrid queries for complex search scenarios\n"
     ]
    }
   ],
   "source": [
    "# Clean up demo indices\n",
    "try:\n",
    "    index.delete()\n",
    "    print(\"Cleaned up svs_demo index\")\n",
    "except:\n",
    "    print(\"- svs_demo index was already deleted or doesn't exist\")\n",
    "\n",
    "# Note: The manual index wasn't created in this demo, so no need to delete it\n",
    "print(\"\\n🎉 SVS-VAMANA demo completed!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"- Try SVS-VAMANA with your own embeddings\")\n",
    "print(\"- Experiment with different compression settings\")\n",
    "print(\"- Compare performance with FLAT and HNSW algorithms\")\n",
    "print(\"- Use hybrid queries for complex search scenarios\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
